---
layout: homepage
---

### About Me

üëã I am a **Ph.D. candidate** in the AI Thrust at The Hong Kong University of Science and Technology, Guangzhou campus. I am fortunate to be advised by [Prof. Xuming Hu @ HKUST](https://xuminghu.github.io/) and [Prof. Raymond Chi-Wing Wong @ HKUST](https://www.cse.ust.hk/~raywong/). I also serve as a **Resident Doctoral Researcher** at [INSAIT](https://insait.ai/), under the supervision of [Prof. Luc Van Gool](https://insait.ai/prof-luc-van-gool/) and [Dr. Danda Paudel](https://insait.ai/dr-danda-paudel/). 

Recently, I have also been collaborating with [Prof. Nicu Sebe @ UNITN](https://disi.unitn.it/~sebe/), [Linfeng Zhang @ SJTU](http://www.zhanglinfeng.tech/), and [Kailun Yang @ HNU](https://www.yangkailun.com/). 

My doctoral research focuses on developing algorithms for robust and interpretable multi-modal learning that span the full spectrum of **perception**, **understanding**, **reasoning**, and **generation**.

Currently, I focus on:
- **Multi-modal Foundation Models**: Designing architectures that align heterogeneous sensory inputs (e.g., vision, language, audio, events) through representation learning and retrieval-augmented generation, enabling unified perception and reasoning.
- **Robust Scene Understanding**: Building models that mimic human perceptual stability under noise, distortion, and viewpoint changes to achieve reliable and interpretable scene comprehension.
- **Debiased Multi-modal Learning**: Developing methods to mitigate unimodal biases inherent in vision-language models and multi-modal LLMs, improving generalization across domains and modalities.
- **Advanced Reasoning for Embodied Intelligence**: Integrating reinforcement learning and geometric priors to enhance spatial reasoning, action prediction, and decision-making in embodied AI agents.
- **Unified Understanding and Generation Models**: Bridging discriminative and generative paradigms to construct systems capable of both understanding and producing multi-modal content coherently and controllably.

<span style="color:red; font-weight:bold">üî• I am actively seeking job opportunities (academia & industry) for Fall 2026!</span>

---

### News

{% include_relative _includes/news.md %}

---

### Invited Talks

- **"Omnidirectional Vision: From Scene Understanding, Spatial Intelligence to Industrial Applications"**  
  *SPIC Energy Science and Technology Research Institute*, Shanghai, China, August 2025.
- **"PANORAMA: Exploring the Industrial Potentials of Omnidirectional Vision"**  
  *Yangtze River Delta International Talent Port*, Wuxi, China, August 2025.
- **"Retrieval-augmented Realistic Image Generation via Self-reflective Contrastive Learning"**  
  *VIVO*, August 2025. Invited talk by [Dr. Kanzhi Wu](https://scholar.google.com.hk/citations?user=N0WHQ2wAAAAJ&hl=zh-CN&oi=ao), Shenzhen, China, August 2025.

---

### Mentorship

**Current:** [Yuanhuiyi Lyu (PhD, HKUST-GZ)](https://qc-ly.github.io/); [Lutao Jiang (PhD, HKUST-GZ)](https://lutao2021.github.io/); [Jialei Chen (PhD, Nagoya)](https://psmobile.github.io/); Mengzhen Chi (PhD, NEU); [Zihao Dongfang (RA, HKUST-GZ)](https://scholar.google.com.hk/citations?hl=zh-CN&user=IvJ4_xsAAAAJ); [Chenfei Liao (MPhil, HKUST-GZ)](https://chenfei-liao.github.io/); Junha Moon (MPhil, HKUST-GZ); [Ziqiao Weng (UG, SCU)](https://katie312.github.io/); Yulong Guo (MS, ZJU); Kaiyu Lei (UG, XJTU); Zhenquan Zhang (MPhil, SCUT); [Boyuan Zheng (MPhil, Tongji)](https://nathandrake67.github.io/zhengby.github.io/); Leyi Sheng (UG, HKUST-GZ)

**Past:** Ding Zhong (MS, Michigan); Zhengxuan Jiang (MPhil, ZJU); Yunhao Luo (PhD, Umich); Tianbo Pan (PhD, NUS); Zijie Lin (MS, USTC)

‚úâÔ∏è <strong>Feel free to contact me for discussion and collaboration!</strong>

---

### Services

{% include_relative _includes/services.md %}


<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=a&t=tt&d=zrl7WjzBxF_qKC05N5OneNhjFigQ9jPab4GJHSWvjkI&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080'></script>
